<h1>Task Description</h1>
<p>
  The goal of the PIR-FIRE Lab is:<ul>
  <li>to facilitate and promote comparative evaluation of Personalized Information Retrieval (IR) by offering research teams a means to evaluate their original personalisation algorithms,
  </li>
  <li>
  to give research teams the means to formally define and evaluate their own novel user profiling approaches for PIR, by providing them with information sources about real user preferences.
  </li>
  </ul>
</p>
<p>
  The PIR-FIRE use data from  <a href="https://stackexchange.com/">StackExchange</a>, a very popular community Question Answering (cQA) platform.
  The dataset is composed of questions, and their answers, collected from fifty communities, which can be categorized under the large umbrella of humanistic communities.  
  The dump is curated and merged to tackle the cQA task as a retrieval task.
</p> 

<p>
Here an example of Question, Answer and related Metadata. Each Question is composed by a <em>Title</em>, which is a brief summary of the question, and a <em>Body</em>, which gives the context and the final question. 
</p> 
<img src="academia_question.png" alt="Example of Question" style="width: 100%; height: 100%">
<p><strong>Question</strong>:
<ul>
  <li>
  <em>Title</em>:What kind of Visa is required to work in Academia in Japan?
</li>
<li>
   <em>Body</em>:

As from title. What kind of visa class do I have to apply for, in order to work as an academic in Japan ?

</li>
</ul>
<strong>Answer</strong>:

This might help or this. Here is the crux of the information:

The period of stay is quoted as 3 years/1 year with the following documents needed:

Passport
One visa application form (nationals of Russia or NIS countries need to submit two visa application forms)
One photograph (nationals of Russia or NIS countries need to submit two photographs)
Certificate of Eligibility (Note) - the original and one copy

This visa applied for Long-term stay for the following occupations:

Working visa: professor, artist, religious activities, journalist, investor/business manager, legal/accounting services, medical services, researcher, instructor, engineer, specialist in humanities/International Services

The algorithm for obtaining the visa is given on the first link I added. 

<p>
<strong>Tags</strong>: job-search, visa, japan
</p>
<p>
<strong>Community</strong>: Academia
</p>
</p>

<p>
  In details, the first edition of PIR-FIRE consist of two tasks:
  <ul>
    <br> 
    <li><a href="#Task1">Task1</a>: Standard Information Retrieval</li>
    <br> 
    <li><a href="#Task2">Task2</a>: Prompt-based Information Retrieval</li>
  </ul>
</p>

<h1>Task 1: Standard Information Retrieval</h1><div id="Task1"></div>

<p>
  The cQA task will be tackled as a standard ad-hoc IR task, where the questions are going to be considered as the queries, and the collection, from which the answers will be retrieved, is composed by all the answers available in the dataset. 
  In this case, personalization can be tackled using any standard or novel technique to create a user profile and inject it in the retrieval model.
  We provide multiple baselines that utilize, as first stage retrievers, both classical approaches such as BM25, and neural approaches based on  <a href="https://huggingface.co/google-bert/bert-base-uncased">BERT-like models</a><a href="#BERT"> [1]</a>. 
  As a second stage, we provide re-rankers, using cross-encoders, like <a href="https://huggingface.co/castorini/monot5-base-msmarco">Mono-T5</a> <a href="#MONOT5">[2]</a>, for non-personalized baselines, and for personalized baselines, using of a mix of tags and historical documents related to the users and weighted according to their importance for the current question.
</p>

<h1>Task 2: Prompt-based Information Retrieval</h1><div id="Task2"></div>


<p>
  The prompt-based baselines personalise the results by using models like <a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct">Phi-3</a> <a href="#PHI">[3]</a> and <a href="https://openai.com/index/gpt-4/">GPT</a> with prompts similar to the following one: 
  <br> 
  To which degree between 0 and 1 does the document <em>DOCUMENT</em> answer the question <em>QUESTION</em>, and is relevant to a user with the following profile <em>USER PROFILE</em>
  <br> 
  <br> 
  The <em>USER PROFILE</em> is a series of user interests that are inferred from their activities and ordered according to their timestamp (most recent first) and importance.
</p>

<head>
   <title>Bibliography</title>
</head>
<body>
   <h1>Bibliography</h1>
   <ol>
      <li>
         <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. <cite>Bert: Pre-training of deep bidirectional transformers for language understanding.</cite>, arXiv preprint arXiv:1810.04805. (2018)</p>
      </li><div id="BERT"></div>
      <li>
         <p>Nogueira, R., Jiang, Z., & Lin, J. <cite>Document ranking with a pretrained sequence-to-sequence model. </cite>, arXiv preprint arXiv:2003.06713. (2020)</p>
      </li><div id="MONOT5"></div>
      <li>
         <p>Abdin, M., Jacobs, S. A., Awan, A. A., Aneja, J., Awadallah, A., Awadalla, H., ... & Zhou, X. <cite>Phi-3 technical report: A highly capable language model locally on your phone.</cite>, arXiv preprint arXiv:2404.14219. (2024)</p>
      </li><div id="PHI"></div>
      
     
   </ol>
</body>




